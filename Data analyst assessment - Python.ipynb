{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdeaf51e",
   "metadata": {},
   "source": [
    "# Microclimate sensors data\n",
    "\n",
    "\n",
    "<span style=\"font-size: 15px;\"> The following task explores the 'microclimate-sensors-data' dataset from the City of Melbourne's open data platform. The dataset contains climate readings from a handful sensors located within Melbourne. The data is updated every fifteen minutes and includes information about wind-speed, direction, temperature, humidity, pollutants, and atmospheric pressure. It is described by the City of Melbourne as being useful to determine variations in microclimate changes throughout the day.  </span>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"font-size: 15px;\"> This task will cover basic exploration and transformation to prepare the data for visualisation in Power BI. You can access the source data as well as information about the dataset from the below link.</span>\n",
    "\n",
    "https://data.melbourne.vic.gov.au/explore/dataset/microclimate-sensors-data/information/\n",
    "\n",
    "<span style=\"font-size: 15px;\"> The activities are not required to be completed 'live'. You can work on it at your pace and in your own time. When completing the task, **you are welcome and encouraged to use ChatGPT, Google, StackOverflow, and any other tool which supports you**. However, please do ensure that you are able to justify/explain the approach you've taken to solving the questions asked. </span>\n",
    "\n",
    "<span style=\"font-size: 15px;\"> There are many ways to solve the same problem correctly. While writing 'perfect' code is nice, don't spend too much time optimising - it's far more important to write code which you understand, is easy for others to interpret, and that you can explain while still getting the correct output. </span>\n",
    "\n",
    "\n",
    "<img src=\"https://www.hobodataloggers.com.au/images/thumbs/0011187_hobo-advanced-weather-station-kit.png\" />\n",
    "\n",
    "\n",
    "*** \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> The first cell of this notebook downloads the data required and loads it to session memory as a dataframe. Please ensure you run this cell to load the file. Alternatively you're welcome to delete this cell if you'd prefer to load it separately however do not modify the data.  You will not be assessed on this.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "url = 'https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/microclimate-sensors-data/exports/csv?lang=en&timezone=Australia%2FMelbourne&use_labels=true&delimiter=%2C'\n",
    "response = requests.get(url)\n",
    "if response.status_code==200:\n",
    "    file_path = 'microclimate_sensors_data.csv'\n",
    "    with open (file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"The file has downloaded to:\", os.getcwd(),\"... with filename:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a538f",
   "metadata": {},
   "source": [
    "### 1. Print the column names of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98abc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231cec4b",
   "metadata": {},
   "source": [
    "### 2. Show the 'shape' of the dataframe\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> In this context 'shape' simply refers to the row/column length of the dataframe</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b2611",
   "metadata": {},
   "source": [
    "### 3. Produce summary statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4043f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958714b",
   "metadata": {},
   "source": [
    "### 4. Check whether there are blanks in the LatLong column. If there are blanks, how many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e98e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df['LatLong'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63118943",
   "metadata": {},
   "source": [
    "### 5. If there are blanks in the LatLong column, populate the blank values with the appropriate coordinates.\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Each sensor will contain at least one valid LatLong coordinate despite other records being missing. You can use these coordinates to populate the blank LatLong cells for a given sensor. There should be one unique LatLong coordinate for each sensor.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LatLong'] = df.groupby('Device_id')['LatLong'].apply(lambda x: x.ffill().bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any blank LatLongs?\n",
    "df[['Device_id','LatLong']].loc[df['LatLong'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4eb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure only one LatLong coordinate per Device_id\n",
    "for device in set(df['Device_id']):\n",
    "    print(device)\n",
    "    print(\"Number of unique coordinates:\", len(df.loc[df['Device_id']==f'{device}']['LatLong'].unique()))\n",
    "    print(\"List of coordinates:\", df.loc[df['Device_id']==f'{device}']['LatLong'].unique())\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb859c7",
   "metadata": {},
   "source": [
    "### 6. How many unique Device_id's are in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['Device_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909cb7a",
   "metadata": {},
   "source": [
    "### 7. How many unique Device_id's contain one or more blank AirTemperature records?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\n",
    "    df['Device_id'].loc[df['AirTemperature'].isna()].unique()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca545382",
   "metadata": {},
   "source": [
    "### 8. What is the largest value of MaximumWindDirection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbc81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(df['MaximumWindDirection'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfbcad",
   "metadata": {},
   "source": [
    "### 9. Is MinimumWindDirection ever greater than MaximumWindDirection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31432537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['MinimumWindDirection'] > df['MaximumWindDirection'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052439f",
   "metadata": {},
   "source": [
    "### 10. Split LatLong into two separate columns named 'Latitude' and 'Longitude'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711fde2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latlong_split = df['LatLong'].str.split(',',expand=True)\n",
    "latlong_split.columns = ['Latitude','Longitude']\n",
    "\n",
    "df = pd.concat([df, latlong_split], axis=1)\n",
    "df.drop(columns=['LatLong'],inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89aa871",
   "metadata": {},
   "source": [
    "### 11. Drop MinimumWindDirection, MaximumWindDirection, and AverageWindDirection from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['MinimumWindDirection', 'MaximumWindDirection', 'AverageWindDirection'],inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc0601c",
   "metadata": {},
   "source": [
    "### 12. Save the dataframe as a .csv to your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee3a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Python_transformed_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

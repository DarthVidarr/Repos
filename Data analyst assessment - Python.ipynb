{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd99113",
   "metadata": {},
   "source": [
    "# Microclimate sensors data\n",
    "\n",
    "\n",
    "<span style=\"font-size: 15px;\"> The following assessment explores the 'microclimate-sensors-data' dataset from the City of Melbourne's open data platform. The assessment will cover basic exploration and transformation to prepare the data for visualisation in Power BI. You can access the source data as well as information about the dataset from the below link.  </span>\n",
    "\n",
    "https://data.melbourne.vic.gov.au/explore/dataset/microclimate-sensors-data/information/\n",
    "\n",
    "\n",
    "<span style=\"font-size: 15px;\"> The dataset contains climate readings from a handful sensors located within Melbourne. The data is updated every fifteen minutes and includes information about wind-speed, direction, temperature, humidity, pollutants, and atmospheric pressure. It is described by the City of Melbourne as being useful to determine variations in microclimate changes throughout the day. </span>\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"font-size: 15px;\"> The assessment is not required to be completed 'live', i.e. you can work on it at your pace and in your own time. When completing the assessment, **you are welcome and encouraged to use ChatGPT, Google, StackOverflow, and any other tool which supports you** since everyone uses these tools on the job. With that in mind, please do ensure that you are able to explain the approach you've taken. </span>\n",
    "\n",
    "\n",
    "<img src=\"https://www.hobodataloggers.com.au/images/thumbs/0011187_hobo-advanced-weather-station-kit.png\" />\n",
    "\n",
    "\n",
    "*** \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> The first cell of this notebook downloads the data required and loads it to session memory as a dataframe. You will not be assessed on this, however please ensure you run this cell to load the file. Alternatively you're welcome to delete this cell if you'd prefer to load it separately however do not modify the data.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fe2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "url = 'https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/microclimate-sensors-data/exports/csv?lang=en&timezone=Australia%2FMelbourne&use_labels=true&delimiter=%2C'\n",
    "response = requests.get(url)\n",
    "if response.status_code==200:\n",
    "    file_path = 'microclimate_sensors_data.csv'\n",
    "    with open (file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"The file has downloaded to:\", os.getcwd(),\"... with filename:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c4ba1",
   "metadata": {},
   "source": [
    "### 1. Print the column names of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8a4f8",
   "metadata": {},
   "source": [
    "### 2. Show the 'shape' of the dataframe\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> In this context 'shape' simply refers to the row/column length of the dataframe</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01781fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a272908",
   "metadata": {},
   "source": [
    "### 3. Produce summary statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41196f2",
   "metadata": {},
   "source": [
    "### 4. Check whether there are blanks in the LatLong column. If there are blanks, how many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68457df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df['LatLong'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f0c291",
   "metadata": {},
   "source": [
    "### 5. If there are blanks in the LatLong column, populate the blank values with the appropriate coordinates.\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Each sensor will contains at least one valid LatLong coordinate despite other records being missing, you can use these coordinates to populate blanks for a given sensor. There should only be one unique LatLong coordinate for each sensor.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67212c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LatLong'] = df.groupby('Device_id')['LatLong'].apply(lambda x: x.ffill().bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469eef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any blank LatLongs?\n",
    "df[['Device_id','LatLong']].loc[df['LatLong'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C\n",
    "for device in set(df['Device_id']):\n",
    "    print(device)\n",
    "    print(\"Number of unique coordinates:\", len(df.loc[df['Device_id']==f'{device}']['LatLong'].unique()))\n",
    "    print(\"List of coordinates:\", df.loc[df['Device_id']==f'{device}']['LatLong'].unique())\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba35fce8",
   "metadata": {},
   "source": [
    "### 6. How many unique Device_id's are in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['Device_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7460621",
   "metadata": {},
   "source": [
    "### 7. How many unique Device_id's contain one or more blank AirTemperature records?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37eb06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\n",
    "    df['Device_id'].loc[df['AirTemperature'].isna()].unique()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838cf4bc",
   "metadata": {},
   "source": [
    "### 8. What is the largest value of MaximumWindDirection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(df['MaximumWindDirection'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2aca9",
   "metadata": {},
   "source": [
    "### 9. Is MinimumWindDirection ever greater than MaximumWindDirection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['MinimumWindDirection'] > df['MaximumWindDirection'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c228ac34",
   "metadata": {},
   "source": [
    "### 10. Split LatLong into two separate columns named 'Latitude' and 'Longitude'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae3c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "latlong_split = df['LatLong'].str.split(',',expand=True)\n",
    "latlong_split.columns = ['Latitude','Longitude']\n",
    "\n",
    "df = pd.concat([df, latlong_split], axis=1)\n",
    "df.drop(columns=['LatLong'],inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26725204",
   "metadata": {},
   "source": [
    "### 11. Drop MinimumWindDirection, MaximumWindDirection, and AverageWindDirection from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da03e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['MinimumWindDirection', 'MaximumWindDirection', 'AverageWindDirection'],inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9b9a1",
   "metadata": {},
   "source": [
    "### 12. Save the dataframe as a .csv to your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aff9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Python_transformed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ffcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
